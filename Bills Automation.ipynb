{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Personal project to read and clasify bills</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Rossum API (Software to read invoices)</li>\n",
    "\n",
    "<li>maximilianovedoya@gmail.com M@xi200122</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read invoces using OCR</h3>\n",
    "<p>it reads images from files folder and creates a corpora in invoces where each files is saved as txt in order to avoid process more than one time each files.</p>\n",
    "\n",
    "<li>it is necessary to read pdf </li>\n",
    "<li>it is necessary to be able to extract invoices from nested directories</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os import walk\n",
    "\n",
    "home='C:/Users/maxim/Dropbox/5. Proyectos personales/10. Bills Automatization/home'\n",
    "\n",
    "#recives the name of the folder of invoices and returns a list of file names. \n",
    "def getfiles(string:str):\n",
    "    os.chdir(home)\n",
    "    f = list()\n",
    "    for (dirpath, dirnames, filenames) in walk(string):\n",
    "        f.extend(filenames)\n",
    "    return f\n",
    "\n",
    "#recives a list of tuples (names,content) and creates a folder with txt files\n",
    "def updatefolder(dic: dict):\n",
    "    os.chdir(home)\n",
    "    try:\n",
    "        os.mkdir('invoices')\n",
    "    except:\n",
    "        pass\n",
    "    os.chdir(home+'/invoices')\n",
    "    for name,content in dic.items():\n",
    "        file=open(name[:-4]+'.txt','w')\n",
    "        file.write(content)\n",
    "        file.close()\n",
    "\n",
    "\n",
    "#it checks whether the files were already processed\n",
    "os.chdir(home)\n",
    "dirnames=list()\n",
    "for (path, dirname, file_name) in walk(home):\n",
    "    try:\n",
    "        dirnames.append(dirname)\n",
    "    except:\n",
    "        pass\n",
    "if 'invoices' in dirnames[0]:\n",
    "    processed_files=getfiles('invoices')\n",
    "    processed_files=[file[:-4]+'.jpg' for file in processed_files]\n",
    "else:\n",
    "    processed_files=list()\n",
    "\n",
    "\n",
    "files=getfiles('files')\n",
    "\n",
    "#Goes through each one of the files and creates a dictionary with names and content. \n",
    "allcontent=list()\n",
    "os.chdir(home+'/files')\n",
    "for file in files:\n",
    "        if not file in processed_files:\n",
    "            img=Image.open(file)\n",
    "            text=pytesseract.image_to_string(img,lang='spa')\n",
    "            striptext = text.replace('\\n\\n', ' ')\n",
    "            striptext = striptext.replace('\\n', ' ')\n",
    "            striptext = striptext.replace(':', ' ')\n",
    "            striptext=striptext.lower()\n",
    "            allcontent.append((file,striptext))\n",
    "        else:\n",
    "            continue \n",
    "    \n",
    "dic={name:content for name,content in allcontent}\n",
    "updatefolder(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a dictionary with all the invoices\n",
    "def get_data():\n",
    "    os.chdir(home)\n",
    "    f = list()\n",
    "    for (dirpath, dirnames, filenames) in walk(home+'/invoices'):\n",
    "        f=filenames\n",
    "    allcontent=list()\n",
    "    os.chdir(home+'/invoices')\n",
    "    for name in f:\n",
    "        file = open(name, 'r')\n",
    "        allcontent.append((name,file.read()))\n",
    "    dic={name:content for name,content in allcontent}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build function to extract informatio from invoices.</h3>\n",
    "<li>it is necessary to Improve the regex expresions</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extratcor(striptext):\n",
    "    import re \n",
    "    data={ 'iva':None,\n",
    "           'fecha':None,\n",
    "           'total':None,\n",
    "           'empresa':None,\n",
    "           'keywords':None,\n",
    "          }\n",
    "\n",
    "    keywords=['encomiendas','pasajes','boletos','latex','pincel']\n",
    "\n",
    "#it is necessary to improve this \n",
    "    iva=r'21,00\\s*%|21\\s*%|iva.{1,4}exento|10,50\\s*%'\n",
    "    iva=re.search(iva,striptext)\n",
    "    if iva:\n",
    "        data['iva']=iva.group(0)\n",
    "    \n",
    "#     importe=r'total\\s*\\$?\\s+(\\d+,?.?\\d+.?\\d{2})'\n",
    "    importe=r'total\\s*\\$?\\s+(\\d{1,3}?\\,?\\d{1,3}?\\,?\\d{1,3}\\.\\d{2})'\n",
    "    importe=re.search(importe,striptext)\n",
    "    if importe:\n",
    "        data['total']=importe.group(1)\n",
    "    else:\n",
    "        importe=r'total\\s*\\$?\\s+(\\d{1,3}?\\.?\\d{1,3}?\\.?\\d{1,3}\\,\\d{2})'\n",
    "        importe=re.search(importe,striptext)\n",
    "        if importe:\n",
    "            data['total']=importe.group(1)\n",
    "    \n",
    "    fecha=r'\\s+(\\d{2}/\\d{2}/\\d{2})'\n",
    "    fecha=re.search(fecha,striptext)\n",
    "    if fecha:\n",
    "        data['fecha']=fecha.group(1)\n",
    "    else:\n",
    "        fecha=r'\\s+(\\d{2}-\\d{2}-\\d{2})'\n",
    "        fecha=re.search(fecha,striptext)\n",
    "        data['fecha']=fecha.group(1)\n",
    "    \n",
    "    tipos=['s.r.l','srl','s.a','sa','s.a.s','sas']\n",
    "    for tipo in tipos:\n",
    "        empresa=r'(\\w+\\s*\\w*\\s*\\w*\\s*\\w*)\\s+'+tipo\n",
    "        empresa=re.search(empresa,striptext)\n",
    "        if empresa:\n",
    "            data['empresa']=empresa.group(0)\n",
    "    \n",
    "    import string\n",
    "    import nltk\n",
    "    from nltk import word_tokenize\n",
    "    text=word_tokenize(striptext)\n",
    "    clean=[word for word in text if word not in nltk.corpus.stopwords.words(\"spanish\")]\n",
    "    clean=[word for word in clean if word not in string.punctuation]\n",
    "    \n",
    "# matches against keywords or fuzzzy keywords inside the text.\n",
    "    from fuzzywuzzy import fuzz\n",
    "    temp_=list()\n",
    "    for word in clean:\n",
    "        for keyword in keywords:\n",
    "            if fuzz.ratio(word, keyword)>=70:\n",
    "                temp_.append(keyword)\n",
    "    if temp_:\n",
    "        data['keywords']=temp_\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxim\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "dic=get_data()\n",
    "temp_=list()\n",
    "for invoice in dic.values():\n",
    "    temp_.append(extratcor(invoice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iva</th>\n",
       "      <th>fecha</th>\n",
       "      <th>total</th>\n",
       "      <th>empresa</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10,50%</td>\n",
       "      <td>23/08/20</td>\n",
       "      <td>3.089,05</td>\n",
       "      <td>bo sa</td>\n",
       "      <td>[encomiendas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iva exento</td>\n",
       "      <td>11/07/20</td>\n",
       "      <td>270.00</td>\n",
       "      <td>2018 sa</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>10-02-20</td>\n",
       "      <td>6124.05</td>\n",
       "      <td>i avenida s.a</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>13-02-20</td>\n",
       "      <td>None</td>\n",
       "      <td>i avenida s.a</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>14-02-20</td>\n",
       "      <td>1497.67</td>\n",
       "      <td>factura avenida s.a</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>10/03/20</td>\n",
       "      <td>3,960.00</td>\n",
       "      <td>00073983 axoft argentina s.a</td>\n",
       "      <td>[encomiendas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>25/03/20</td>\n",
       "      <td>None</td>\n",
       "      <td>descripción sa</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>17/01/20</td>\n",
       "      <td>742.98</td>\n",
       "      <td>avenida sa</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>05-10-20</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>21%</td>\n",
       "      <td>29/02/20</td>\n",
       "      <td>18,341.24</td>\n",
       "      <td>empresa rio uruguay s.r.l</td>\n",
       "      <td>[encomiendas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>iva exento</td>\n",
       "      <td>05/04/20</td>\n",
       "      <td>10,560.00</td>\n",
       "      <td>empresas asociadas central argentino srl</td>\n",
       "      <td>[boletos, pasajes, boletos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>iva exento</td>\n",
       "      <td>05/04/20</td>\n",
       "      <td>10,560.00</td>\n",
       "      <td>empresas asociadas central argentino srl</td>\n",
       "      <td>[boletos, pasajes, boletos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>21,00 %</td>\n",
       "      <td>23/02/20</td>\n",
       "      <td>1.745,45</td>\n",
       "      <td>2016   razón social  empresa s.a</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           iva     fecha      total                                   empresa  \\\n",
       "0       10,50%  23/08/20   3.089,05                                     bo sa   \n",
       "1   iva exento  11/07/20     270.00                                   2018 sa   \n",
       "2         None  10-02-20    6124.05                             i avenida s.a   \n",
       "3         None  13-02-20       None                             i avenida s.a   \n",
       "4         None  14-02-20    1497.67                       factura avenida s.a   \n",
       "5         None  10/03/20   3,960.00              00073983 axoft argentina s.a   \n",
       "6         None  25/03/20       None                            descripción sa   \n",
       "7         None  17/01/20     742.98                                avenida sa   \n",
       "8         None  05-10-20       None                                      None   \n",
       "9          21%  29/02/20  18,341.24                 empresa rio uruguay s.r.l   \n",
       "10  iva exento  05/04/20  10,560.00  empresas asociadas central argentino srl   \n",
       "11  iva exento  05/04/20  10,560.00  empresas asociadas central argentino srl   \n",
       "12     21,00 %  23/02/20   1.745,45          2016   razón social  empresa s.a   \n",
       "\n",
       "                       keywords  \n",
       "0                 [encomiendas]  \n",
       "1                          None  \n",
       "2                          None  \n",
       "3                          None  \n",
       "4                          None  \n",
       "5                 [encomiendas]  \n",
       "6                          None  \n",
       "7                          None  \n",
       "8                          None  \n",
       "9                 [encomiendas]  \n",
       "10  [boletos, pasajes, boletos]  \n",
       "11  [boletos, pasajes, boletos]  \n",
       "12                         None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df=pd.DataFrame(temp_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build a list of stopwords to clean the text get keywords.</h3>\n",
    "<li>It is necessary to check the spelling of words and include more invoices so it becomes better</li>\n",
    "<li>Build something to store all stopwords and keywords into a file, and also to allow Human filter keywords, allowing the software to 'learn' from that </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(get_data().values())\n",
    "textos=''\n",
    "for item in data:\n",
    "    textos+=item\n",
    "\n",
    "#Takes a word and strip all non-alphabetic char  \n",
    "def clean_word(word):\n",
    "    temp_=''\n",
    "    for item in word:\n",
    "        if item.isalpha():\n",
    "            temp_+=item \n",
    "    return temp_    \n",
    "\n",
    "#takes an string, a returns a list of potential keywords \n",
    "def clean_numbers(textos):\n",
    "    import string\n",
    "    import nltk\n",
    "    from nltk import word_tokenize\n",
    "    striptext = textos.replace('\\n\\n', ' ')\n",
    "    striptext = striptext.replace('\\n', ' ')\n",
    "    text=word_tokenize(striptext,'spanish')\n",
    "    clean=[word for word in text if word not in nltk.corpus.stopwords.words(\"spanish\")]\n",
    "    clean=[word for word in clean if word not in string.punctuation] \n",
    "    for item in range(len(clean)):\n",
    "        clean[item]=clean_word(clean[item])\n",
    "    clean=[word for word in clean if not word.isnumeric()]\n",
    "    return clean\n",
    "\n",
    "#takes a list of words form texts and returns a list of stopwords, words that are not keywords\n",
    "def nokeywords(list_):\n",
    "    from nltk.probability import FreqDist\n",
    "    list_=FreqDist(list_)\n",
    "    stopwords=list()\n",
    "    for word,freq in list_.most_common(100000):\n",
    "        if freq>3:\n",
    "            stopwords.append(word)\n",
    "    return stopwords\n",
    "\n",
    "stopwords=nokeywords(clean_numbers(textos))\n",
    "p_keywords=[word for word in clean_numbers(data[6]) if word not in stopwords]\n",
    "p_keywords=[word for word in p_keywords if len(word)>4 and len(word)<=13 ]\n",
    "\n",
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colon\n",
      "colon\n",
      "notkeyword\n",
      "documento\n",
      "documento\n",
      "notkeyword\n",
      "guitierrez\n",
      "guitierrez\n",
      "notkeyword\n",
      "hijos\n",
      "hijos\n",
      "notkeyword\n",
      "colón\n",
      "colón\n",
      "notkeyword\n",
      "actividad\n",
      "actividad\n",
      "notkeyword\n",
      "señores\n",
      "señores\n",
      "notkeyword\n",
      "jamenez\n",
      "jamenez\n",
      "notkeyword\n",
      "nocmiente\n",
      "nocmiente\n",
      "notkeyword\n",
      "narcos\n",
      "narcos\n",
      "notkeyword\n",
      "telefonofax\n",
      "telefonofax\n",
      "notkeyword\n",
      "cplocalidad\n",
      "cplocalidad\n",
      "notkeyword\n",
      "comercial\n",
      "comercial\n",
      "notkeyword\n",
      "consunidor\n",
      "consunidor\n",
      "notkeyword\n",
      "final\n",
      "final\n",
      "notkeyword\n",
      "horario\n",
      "horario\n",
      "notkeyword\n",
      "atención\n",
      "atención\n",
      "notkeyword\n",
      "renped\n",
      "renped\n",
      "notkeyword\n",
      "descripción\n",
      "descripción\n",
      "notkeyword\n",
      "ppecio\n",
      "ppecio\n",
      "notkeyword\n",
      "medida\n",
      "medida\n",
      "notkeyword\n",
      "bonobom\n",
      "bonoboms\n",
      "chocolate\n",
      "chocolates\n",
      "mercadopago\n",
      "mercadopago\n",
      "notkeyword\n",
      "local\n",
      "local\n",
      "notkeyword\n",
      "colon\n",
      "colon\n",
      "notkeyword\n",
      "facturado\n",
      "facturado\n",
      "notkeyword\n",
      "pesos\n",
      "pesos\n",
      "notkeyword\n",
      "catorce\n",
      "catorce\n",
      "notkeyword\n"
     ]
    }
   ],
   "source": [
    "keywords=[]\n",
    "for word in p_keywords:\n",
    "    print(word)\n",
    "    if input(word):\n",
    "        keywords.append(word)\n",
    "    else:\n",
    "        print('notkeyword')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bonobom', 'chocolate']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(striptext):\n",
    "#     import re \n",
    "#     data={ 'iva':None,\n",
    "#            'fecha':None,\n",
    "#            'total':None,\n",
    "#            'empresa':None,\n",
    "#            'keywords':None,\n",
    "#           }\n",
    "\n",
    "#     keywords=['encomiendas','pasajes','boletos','latex','pincel']\n",
    "    \n",
    "#     iva=r'21,00\\s*%|21\\s*%|iva.{1,4}exento|10,50\\s*%'\n",
    "#     iva=re.search(iva,striptext)\n",
    "#     if iva:\n",
    "#         data['iva']=iva.group(0)\n",
    "    \n",
    "#     importe=r'total\\s*\\$?\\s+(\\d{1,3}?\\,?\\d{1,3}?\\,?\\d{1,3}\\.\\d{2})'\n",
    "#     importe=re.search(importe,striptext)\n",
    "#     if importe:\n",
    "#         data['total']=importe.group(1)\n",
    "#     else:\n",
    "#         importe=r'total\\s*\\$?\\s+(\\d{1,3}?\\.?\\d{1,3}?\\.?\\d{1,3}\\,\\d{2})'\n",
    "#         importe=re.search(importe,striptext)\n",
    "#         if importe:\n",
    "#             data['total']=importe.group(1)\n",
    "\n",
    "#     fecha=r'\\s+(\\d{2}/\\d{2}/\\d{2})'\n",
    "#     fecha=re.search(fecha,striptext)\n",
    "#     if fecha:\n",
    "#         data['fecha']=fecha.group(1)\n",
    "#     else:\n",
    "#         fecha=r'\\s+(\\d{2}-\\d{2}-\\d{2})'\n",
    "#         fecha=re.search(fecha,striptext)\n",
    "#         data['fecha']=fecha.group(1)\n",
    "\n",
    "#     tipos=['s.r.l','srl','s.a','sa','s.a.s','sas']\n",
    "#     for tipo in tipos:\n",
    "#         empresa=r'(\\w+\\s*\\w*\\s*\\w*\\s*\\w*)\\s+'+tipo\n",
    "#         empresa=re.search(empresa,striptext)\n",
    "#         if empresa:\n",
    "#             data['empresa']=empresa.group(0)\n",
    "    \n",
    "#     import string\n",
    "#     from nltk import word_tokenize\n",
    "#     text=word_tokenize(striptext)\n",
    "#     clean=[word for word in text if word not in nltk.corpus.stopwords.words(\"spanish\")]\n",
    "#     clean=[word for word in clean if word not in string.punctuation]\n",
    "    \n",
    "#     #matches against keywords or fuzzzy keywords inside the text.\n",
    "#     from fuzzywuzzy import fuzz\n",
    "#     temp_=list()\n",
    "#     for word in clean:\n",
    "#         for keyword in keywords:\n",
    "#             if fuzz.ratio(word, keyword)>70:\n",
    "#                 temp_.append(keyword)\n",
    "#     if temp_:\n",
    "#         data['keywords']=temp_\n",
    "    \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pdf2image import convert_from_path, convert_from_bytes\n",
    "# from pdf2image.exceptions import (\n",
    "#     PDFInfoNotInstalledError,\n",
    "#     PDFPageCountError,\n",
    "#     PDFSyntaxError\n",
    "# )\n",
    "\n",
    "# images = convert_from_path('\\TestFiles\\test.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
